---
title: "Getting_and_Cleaning_Data"
author: "Mike Talley"
date: "3/21/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

All steps taken to process and clean data should be carefully documented, as it may have downstream effects on the data analysis. 

# Components of Tidy Data

There are four things you should have when you are done processing data.

1. The raw data
2. A tidy data set
3. A code book describing each variable and its values in the tidy data set. 
4. An explicit and exact recipe you used to go from 1 -> 2 -> 3.

## The Raw Data

Data is only raw (for you) if...

1. You ran no software on the data.
2. You did not manipulate any of the numbers in the data.
3. You did not remove any data from the data set.
4. You did not summarize the data in any way. 

## The Tidy Data

1. Each variable you measure should be in one column.
2. Each different observation of that variable should be a different row. 
3. There should be one table for each "kind" of variable.
4. If you have multiple tables, they should include a column that allows them to be linked.

You should always make an effort to include a row at the top of the table with descriptive column names. You should also aim to have one table per file, rather than multiple tables like people often do in Excel files. 

## The Code Book

1. Information about the variables (including units!) in the data set not contained in the tidy dta.
2. Information about the summary choices you made. 
3. Information about the experimental study design you used. 

Many people choose to format this document in a Word/text file. RMarkdown works great for this. 
There should also be a section called "Study Design" that has a thorough description of how you collected the data, along with a section called "Code Book", that describes each variable and its units. 

## The Instruction List

1. Ideally a computer script (R, Python, etc.)
2. Input is the raw data
3. Output is the processed, tidy data
4. There are NO parameters to the script. It should work just fine on its own. 

In some cases, R will not do EVERYTHING you need it to when cleaning the data. If that's true, you should write out clear instructions that go above and beyond the necessary amount of detail, to ensure the recipe is still able to be followed. 

  *Example: Step 1: Take the raw file, run version 3.1.2 of ____ software using parameters ___.*
  
# Downloading Files

We need to use R to select files, rather than picking them by hand, because it allows this step to also be reproducible. 

## Finding The Files and Where to Find Them

When using R, we will use "directories", or specific locations in our computer space. We can use `getwd()` to check what directory we are currently in, and `setwd()` to change/set the path we want to be working in. An *absolute* path would be naming the directory itself, where as a *relative* path would set a general directory, and then navigate up or down in the command to reach the desired final destination.

- Relative: `setwd("./data"), setwd("../)` to naviagate up
- Absolute: `setwd("./data")` to be in an exact place. 

To check if a directory exists, we can use the `file.exists()` command, and if it doesn't, we can create one with `dir.create()`. Below is a function you could use to check for and create a directory all at once. 

```{r eval = FALSE}
if (!file.exists("data")) {
  dir.create("data")
}
```

## Getting Data From the Internet

We can download files from the internet either by hand, or with R, but as always, using scripts to do things makes it more reproducible. We would use the `download.file()` function to achieve this. It's important to outline specific parameters such as; *url*, *destfile*, and *method*. This command can download most files, regardless of their format. 

## Reading Excel Files

Most data scientists dislike Excel, but because it is so common, it's useful to know how to read these files into R.

`write.xlsx` will output an Excel file.
`read.xlsx` or `read.xlsx2` are used to read in the files. 

In general, storing in CSV or TAB files is better, as they are easier to read and do not require other users to have Excel.

## Reading XML

*Extensible Markup Language (XML)*

This is frequently used to store structured data, particularly data obtained from web scraping. There are two parts to this: Markup, which is labels to give the text structure, and Content, which is the actual text itself. 

Tags correspond to general labels.
- Start tags: <section>
- End tags: </section>
- Empty tags: <line-break />

Elements are specific examples of tags.
- <Greeting> Hello, world </Greeting>

Attributes are components of the label.
```{r eval = FALSE}
- <img src="jeff.jpg" alt="instructor"/>
- <step number="3"> Connect A to B. </step>
```

*Much more detailed notes on this are available in the lecture content.*

## Reading JSON

*Javascript Object Notation (JSON)*

This is a common format for data from APIs (applications programming interfaces).
Again, more information can be found in the lecture.

# The data.table Package
```{r echo = FALSE}
library(data.table)
```
Data table is often a lot faster alternative to using traditional data frames in R. All functions that work on data frames will also work on data tables, but because it's written in C, it is much faster, particularly at subsetting, grouping and updating. 
Using the `table()` function, you can get a summary of all the data tables in memory. 

***It's important to note that there is a different set of syntax for data.tables***

## Subsetting

```{r}
## Create a dataframe
DT <- data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))

## A specific row
DT[2,]

## When you want specific values in a column
DT[DT$y == "a", ]

## If you don't specify, it automatically returns rows
DT[c(2,3)]

## This is where it diverges. Traditional calls to subset columns do NOT work
DT[, c(2,3)]
```

Traditionally, "expressions" in R are statements enclosed in curly brackets. In data tables however, anything after the comma is an expression. If you pass a list into a data table call, it will evaluate the object. Note that in the example below, you do not need to put column names in parenthesis, as R will just recognize them by name. 

```{r}
## Get the mean of column x, and sum of column z
DT[, list(mean(x), sum(z))]

## Create a table out of column y
DT[, table(y)]
```

## Adding New Columns

```{r}
## Column w is equal to column z squared.
DT[, w:= z^2]
```

One of the nuances to data tables is that they do not create a new memory object. When editing a data FRAME, a new object is stored to the memory, which could bog a computer down with large data sets. Data TABLES however do not, they just edit it, which allows you to more easily work with large data sets. You must be careful when connecting objects though. Because copies are not made, editing object one will automatically edit object two. If you want to make a copy, you will need to explicity say so. 

## Multiple Operations

In the code below, we can do a multi-step operation at once. Inside of the curly brackets, we are assigning the value of (x+z) to the temporary object `tmp`. After the semicolon, we then get the log2 of `tmp + 5`. Because that is the last thing listed in the expression, it is what will be returned. 

```{r}
DT[, m:= {tmp <- (x+z); log2(tmp+5)}]
```

## plyr Like Operations

```{r}
## Creating a vector that returns TRUE, when x is > 0
DT[, a:= x>0]

## For values where a = TRUE, get mean(x+w). Get a different mean(x+w) for when a = FALSE. We are grouping this function by a.
DT[, b:= mean(x+w), by = a]
```

## Special Variables

`.N` is an integer of length 1, containing the number of times something appears. The .N operation is much faster than the $ equivalent in a data frame. 

```{r}
## Data table with a LOT of letters. 
DTlet <- data.table(x = sample(letters[1:3], 1E5, TRUE))

## How many times does each x value appear
DT[, .N, by = x]
```

## Keys

Keys are unique to data tables, and allow you to quickly reference and subset certain things, along with other useful functions. Below we create a table, and set the key to the `x` column. Then when we go to subset the whole table, it searches for the value 'a' within the predefined *key*.

```{r}
DTkey <- data.table(x = rep(c("a", "b", "c"), each = 100), y =  rnorm(300))
setkey(DTkey, x)
DTkey['a']
```

You can also merge data tables together, as long as they have the same vector / column somewhere in there.

```{r}
DT1 <- data.table(x = c('a', 'a', 'b', 'dt1'), y = 1:4)
DT2 <- data.table(x = c('a', 'b', 'dt2'), z = 5:7)
setkey(DT1, x); setkey(DT2, x)
merge(DT1, DT2)
```




